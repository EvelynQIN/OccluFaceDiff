{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from transformers import Wav2Vec2Processor\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4d2f9e342b4627ba5f78c86da8d1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db51760b26f240d488c5dda8a18b099a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0ff414bfe24dc4ab42b9df15cacb98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c729ebc4a1ec456db82caeb74809bd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/292 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a867780e414b789087e26c679a6066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_processor = Wav2Vec2Processor.from_pretrained(\n",
    "        \"facebook/hubert-xlarge-ls960-ft\")  # HuBERT uses the processor of Wav2Vec 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49600,)\n",
      "secs: 3.1\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "audio_path = 'dataset/multiface/m--20171024--0000--002757580--GHS/audio/SEN_are_you_looking_for_employment.wav'\n",
    "speech_array, sampling_rate = librosa.load(audio_path, sr=16000)\n",
    "audio_values = np.squeeze(audio_processor(speech_array, return_tensors=None, padding=\"longest\",\n",
    "                            sampling_rate=sampling_rate).input_values)\n",
    "print(audio_values.shape)\n",
    "print(f\"secs: {audio_values.shape[0] / sampling_rate}\")\n",
    "print(f\"{type(audio_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read MEAD processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/mead_25fps/processed/metadata.pkl', 'rb') as f:\n",
    "    version = pickle.load(f)\n",
    "    video_list = pickle.load(f)\n",
    "    video_metas = pickle.load(f)\n",
    "    annotation_list = pickle.load(f)    # None\n",
    "    frame_lists = pickle.load(f)    # None\n",
    "    try:\n",
    "        audio_metas = pickle.load(f)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('M003/video/front/angry/level_1/001.mp4'),\n",
       " PosixPath('M003/video/front/angry/level_1/002.mp4')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fps': '25/1',\n",
       "  'width': 1920,\n",
       "  'height': 1080,\n",
       "  'num_frames': 83,\n",
       "  'bit_rate': '7402260',\n",
       "  'bits_per_raw_sample': '8'},\n",
       " {'fps': '25/1',\n",
       "  'width': 1920,\n",
       "  'height': 1080,\n",
       "  'num_frames': 67,\n",
       "  'bit_rate': '7245600',\n",
       "  'bits_per_raw_sample': '8'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_metas[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of cam : (1, 83, 3)\n",
      "shape of exp : (1, 83, 100)\n",
      "shape of global_pose : (1, 83, 3)\n",
      "shape of jaw : (1, 83, 3)\n",
      "shape of shape : (1, 83, 300)\n"
     ]
    }
   ],
   "source": [
    "filename = 'dataset/mead_25fps/processed/reconstructions/EMICA-MEAD_flame2020/M003/front/angry/level_1/001/shape_pose_cam.hdf5'\n",
    "data_dict = {}\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    for k in f.keys():\n",
    "        print(f\"shape of {k} : {f[k].shape}\")\n",
    "        data_dict[k] = torch.from_numpy(f[k][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['exp'] = data_dict['exp'][...,:50]\n",
    "data_dict['pose'] = torch.cat([data_dict['global_pose'], data_dict['jaw']], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of images : (88, 3, 224, 224)\n",
      "shape of img_masks : (88, 224, 224)\n",
      "shape of lmk_2d : (88, 478, 2)\n",
      "shape of valid_frames_idx : (88,)\n"
     ]
    }
   ],
   "source": [
    "filename = 'cropped_frames.hdf5'\n",
    "data_dict = {}\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    for k in f.keys():\n",
    "        print(f\"shape of {k} : {f[k].shape}\")\n",
    "        data_dict[k] = f[k][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lmk_on_image(lmks, img, out_path, color=(0,0,255)):\n",
    "    # draw landmarks on the image\n",
    "    h, w, c = img.shape\n",
    "    for px in lmks[:,:2]:\n",
    "        x, y = int(px[0]), int(px[1])\n",
    "        if 0 <= x < w and 0 <=y < h:\n",
    "            cv2.circle(img, (x, y), 1, color, 1)\n",
    "    cv2.imwrite(out_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check flame render correspondance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import get_cfg_defaults \n",
    "from utils.data_util import batch_orth_proj\n",
    "from model.FLAME import FLAME_mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg_defaults().model\n",
    "flame = FLAME_mediapipe(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMICA_rec_to_lmk_2d(flame, frame_id, data_dict):\n",
    "    shape = data_dict['shape'][:,frame_id]\n",
    "    exp = data_dict['exp'][:,frame_id]\n",
    "    pose = data_dict['pose'][:,frame_id]\n",
    "    verts, lmk_3d = flame(shape, exp, pose)\n",
    "    print(lmk_3d.shape) \n",
    "\n",
    "    cam = data_dict['cam'][:,frame_id]\n",
    "    lmk2d_pred = batch_orth_proj(lmk_3d, cam)[:, :, :2]\n",
    "    lmk2d_pred[:, :, 1:] = -lmk2d_pred[:, :, 1:]\n",
    "    print(lmk2d_pred.shape)\n",
    "\n",
    "    lmk2d_pred = lmk2d_pred[0] * 112 + 112\n",
    "    return lmk2d_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correspondances of MEAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import os \n",
    "import glob\n",
    "import pickle\n",
    "import h5py\n",
    "from skimage.transform import estimate_transform, warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "## test mediapipe original landmarks on the original images\n",
    "img_path = f'dataset/mead_25fps/processed/images/M003/front/angry/level_1/00000{frame_id+1}.png'\n",
    "img = cv2.imread(img_path)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 478, 3)\n",
      "(83, 478, 2)\n",
      "(83, 478, 2)\n"
     ]
    }
   ],
   "source": [
    "lmk_aligned_path = 'dataset/mead_25fps/processed/landmarks_original/mediapipe/M003/front/angry/level_1/001'\n",
    "with open(os.path.join(lmk_aligned_path, 'landmarks_original.pkl'), 'rb') as f:\n",
    "    lmks_original = pickle.load(f)\n",
    "lmks_original_478 = np.asarray(lmks_original).squeeze(1)\n",
    "print(lmks_original_478.shape)\n",
    "\n",
    "with open(os.path.join(lmk_aligned_path, 'landmarks.pkl'), 'rb') as f:\n",
    "    landmark_478 = pickle.load(f)\n",
    "landmark_478 = np.asarray(landmark_478).squeeze(1)\n",
    "print(landmark_478.shape)\n",
    "\n",
    "with open(os.path.join(lmk_aligned_path, 'landmarks_aligned_video_smoothed.pkl'), 'rb') as f:\n",
    "    landmark_478_smoothed = pickle.load(f)\n",
    "landmark_478_smoothed = np.asarray(landmark_478_smoothed)\n",
    "print(landmark_478_smoothed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point2bbox(center, size):\n",
    "    size2 = size / 2\n",
    "\n",
    "    src_pts = np.array(\n",
    "        [[center[0] - size2, center[1] - size2], [center[0] - size2, center[1] + size2],\n",
    "         [center[0] + size2, center[1] - size2]])\n",
    "    return src_pts\n",
    "\n",
    "def point2transform(center, size, target_size_height, target_size_width):\n",
    "    src_pts = point2bbox(center, size)\n",
    "    dst_pts = np.array([[0, 0], [0, target_size_width - 1], [target_size_height - 1, 0]])\n",
    "    tform = estimate_transform('similarity', src_pts, dst_pts)\n",
    "    return tform\n",
    "\n",
    "def warp_image_from_lmk(\n",
    "        landmarks, \n",
    "        img, \n",
    "        scale=1.35, \n",
    "        bb_center_shift_x=0., \n",
    "        bb_center_shift_y=-0.1,\n",
    "        image_size=224):    # defaults from EMOTE preprocessing script\n",
    "    left = np.min(landmarks[:, 0])\n",
    "    right = np.max(landmarks[:, 0])\n",
    "    top = np.min(landmarks[:, 1])\n",
    "    bottom = np.max(landmarks[:, 1])\n",
    "\n",
    "    old_size = (right - left + bottom - top) / 2 * 1.1\n",
    "    center_x = right - (right - left) / 2.0 \n",
    "    center_y = bottom - (bottom - top) / 2.0\n",
    "    center = np.array([center_x, center_y])\n",
    "\n",
    "    center[0] += abs(right-left)*bb_center_shift_x\n",
    "    center[1] += abs(bottom-top)*bb_center_shift_y\n",
    "\n",
    "    size = int(old_size * scale)\n",
    "\n",
    "    tform = point2transform(center, size, image_size, image_size)\n",
    "    output_shape = (image_size, image_size)\n",
    "    dst_image = warp(img, tform.inverse, output_shape=output_shape, order=3)\n",
    "    dst_landmarks = tform(landmarks[:, :2])\n",
    "\n",
    "    return dst_image, dst_landmarks\n",
    "\n",
    "def draw_lmk_on_image(lmks, img, out_path, color=(0,0,255)):\n",
    "    # draw landmarks on the image\n",
    "    h, w, c = img.shape\n",
    "    for px in lmks[:,:2]:\n",
    "        x, y = int(px[0]), int(px[1])\n",
    "        if 0 <= x < w and 0 <=y < h:\n",
    "            cv2.circle(img, (x, y), 1, color, 1)\n",
    "    cv2.imwrite(out_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "dst_image, dst_landmarks = warp_image_from_lmk(lmks_original_478[frame_id], img, bb_center_shift_y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst_landmarks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_warped = (dst_image * 255).astype(np.uint8)\n",
    "draw_lmk_on_image(landmark_478[frame_id], img_warped.copy(), \"test_mediapipe_warp.png\", (255,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 105, 3])\n",
      "torch.Size([1, 105, 2])\n"
     ]
    }
   ],
   "source": [
    "img_warped = (dst_image * 255).astype(np.uint8)\n",
    "lmk2d_pred = EMICA_rec_to_lmk_2d(flame, frame_id, data_dict)\n",
    "draw_lmk_on_image(lmk2d_pred, img_warped.copy(), \"test_mediapipe_rec_render_yshift0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_img = np.zeros((224, 224, 3)).astype(np.uint8)\n",
    "draw_lmk_on_image(dst_landmarks, blank_img, \"test_mediapipe_lmk_align_with_rec.png\", (0,0,255))\n",
    "draw_lmk_on_image(lmk2d_pred, blank_img, \"test_mediapipe_lmk_align_with_rec.png\", (255,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_lmk_on_image(landmark_478_smoothed[0], img_warped.copy(), \"test_mediapipe_smoothed_478.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 68, 2)\n"
     ]
    }
   ],
   "source": [
    "# check FAN 68 landmarks\n",
    "lmk_path = 'dataset/mead_25fps/processed/landmarks_aligned/fan/M003/front/angry/level_1/001/landmarks.pkl'\n",
    "with open(lmk_path, 'rb') as f:\n",
    "    lmk_68 = pickle.load(f)\n",
    "print(lmk_68.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmk_68_224 = lmk_68[0].copy() * 224\n",
    "draw_lmk_on_image(lmk_68_224, img_warped.copy(), \"test_fan_aligned.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "X= np.random.rand(100, 1000, 1000).astype('float32')\n",
    "y = np.random.rand(1, 1000, 1000).astype('float32')\n",
    "\n",
    "# Create a new file\n",
    "f = h5py.File('test_h5.hdf5', 'w')\n",
    "f.create_dataset('X_train', data=X)\n",
    "f.create_dataset('y_train', data=y)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train : (100, 1000, 1000)\n",
      "<class 'numpy.ndarray'>\n",
      "shape of y_train : (1, 1000, 1000)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('test_h5.hdf5', \"r\") as f:\n",
    "    for k in f.keys():\n",
    "        print(f\"shape of {k} : {f[k].shape}\")\n",
    "        print(type(f[k][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 86,  74,  75,  76,  66,  94,  93,  92, 104,  85,  71,  70,  69,\n",
       "        65,  87,  88,  89, 103,  91,  90])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.MediaPipeLandmarkLists import * \n",
    "UPPER_LIP_EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_INDICES[UPPER_LIP_EM[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test audio input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "import librosa\n",
    "import numpy as np  \n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"/local/home/yaqqin/Downloads/013.m4a\" # \"dataset/mead_25fps/original_data/M003/audio/angry/level_1/001.m4a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.221375"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speech_array) / sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_values = audio_processor(\n",
    "    speech_array, \n",
    "    return_tensors='pt', \n",
    "    padding=\"longest\",\n",
    "    sampling_rate=sampling_rate).input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 51542])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.221375"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_values.shape[1] / sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.wav2vec import Wav2Vec2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27e846b36474802842b19e513212730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 83, 1024])\n"
     ]
    }
   ],
   "source": [
    "wav2vec = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "wav2vec.feature_extractor._freeze_parameters()\n",
    "wav2vec.to('cuda')\n",
    " \n",
    "audio_input = audio_values.float().to('cuda')\n",
    "with torch.no_grad():\n",
    "    audio_emb = wav2vec(audio_input, frame_num = 83).last_hidden_state.cpu()\n",
    "    print(audio_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test motion prior checkpoint FLINTV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from munch import Munch, munchify\n",
    "from model.motion_prior import L2lVqVae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'pretrained/MotionPrior/models/FLINTv2/checkpoints/model-epoch=0758-val/loss_total=0.113977119327.ckpt'\n",
    "ckpt = torch.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['motion_encoder.squasher.0.0.weight', 'motion_encoder.squasher.0.0.bias', 'motion_encoder.squasher.0.2.weight', 'motion_encoder.squasher.0.2.bias', 'motion_encoder.squasher.0.2.running_mean', 'motion_encoder.squasher.0.2.running_var', 'motion_encoder.squasher.0.2.num_batches_tracked', 'motion_encoder.squasher.1.0.weight', 'motion_encoder.squasher.1.0.bias', 'motion_encoder.squasher.1.2.weight', 'motion_encoder.squasher.1.2.bias', 'motion_encoder.squasher.1.2.running_mean', 'motion_encoder.squasher.1.2.running_var', 'motion_encoder.squasher.1.2.num_batches_tracked', 'motion_encoder.squasher.2.0.weight', 'motion_encoder.squasher.2.0.bias', 'motion_encoder.squasher.2.2.weight', 'motion_encoder.squasher.2.2.bias', 'motion_encoder.squasher.2.2.running_mean', 'motion_encoder.squasher.2.2.running_var', 'motion_encoder.squasher.2.2.num_batches_tracked', 'motion_encoder.encoder_transformer.layers.0.self_attn.in_proj_weight', 'motion_encoder.encoder_transformer.layers.0.self_attn.in_proj_bias', 'motion_encoder.encoder_transformer.layers.0.self_attn.out_proj.weight', 'motion_encoder.encoder_transformer.layers.0.self_attn.out_proj.bias', 'motion_encoder.encoder_transformer.layers.0.linear1.weight', 'motion_encoder.encoder_transformer.layers.0.linear1.bias', 'motion_encoder.encoder_transformer.layers.0.linear2.weight', 'motion_encoder.encoder_transformer.layers.0.linear2.bias', 'motion_encoder.encoder_transformer.layers.0.norm1.weight', 'motion_encoder.encoder_transformer.layers.0.norm1.bias', 'motion_encoder.encoder_transformer.layers.0.norm2.weight', 'motion_encoder.encoder_transformer.layers.0.norm2.bias', 'motion_encoder.encoder_linear_embedding.weight', 'motion_encoder.encoder_linear_embedding.bias', 'motion_encoder.mean.weight', 'motion_encoder.mean.bias', 'motion_encoder.logvar.weight', 'motion_encoder.logvar.bias', 'motion_decoder.expander.0.0.weight', 'motion_decoder.expander.0.0.bias', 'motion_decoder.expander.0.2.weight', 'motion_decoder.expander.0.2.bias', 'motion_decoder.expander.0.2.running_mean', 'motion_decoder.expander.0.2.running_var', 'motion_decoder.expander.0.2.num_batches_tracked', 'motion_decoder.expander.1.0.weight', 'motion_decoder.expander.1.0.bias', 'motion_decoder.expander.1.2.weight', 'motion_decoder.expander.1.2.bias', 'motion_decoder.expander.1.2.running_mean', 'motion_decoder.expander.1.2.running_var', 'motion_decoder.expander.1.2.num_batches_tracked', 'motion_decoder.expander.2.0.weight', 'motion_decoder.expander.2.0.bias', 'motion_decoder.expander.2.2.weight', 'motion_decoder.expander.2.2.bias', 'motion_decoder.expander.2.2.running_mean', 'motion_decoder.expander.2.2.running_var', 'motion_decoder.expander.2.2.num_batches_tracked', 'motion_decoder.decoder_transformer.layers.0.self_attn.in_proj_weight', 'motion_decoder.decoder_transformer.layers.0.self_attn.in_proj_bias', 'motion_decoder.decoder_transformer.layers.0.self_attn.out_proj.weight', 'motion_decoder.decoder_transformer.layers.0.self_attn.out_proj.bias', 'motion_decoder.decoder_transformer.layers.0.linear1.weight', 'motion_decoder.decoder_transformer.layers.0.linear1.bias', 'motion_decoder.decoder_transformer.layers.0.linear2.weight', 'motion_decoder.decoder_transformer.layers.0.linear2.bias', 'motion_decoder.decoder_transformer.layers.0.norm1.weight', 'motion_decoder.decoder_transformer.layers.0.norm1.bias', 'motion_decoder.decoder_transformer.layers.0.norm2.weight', 'motion_decoder.decoder_transformer.layers.0.norm2.bias', 'motion_decoder.decoder_linear_embedding.weight', 'motion_decoder.decoder_linear_embedding.bias', 'motion_decoder.cross_smooth_layer.weight', 'motion_decoder.cross_smooth_layer.bias', 'motion_decoder.post_transformer_linear.weight', 'motion_decoder.post_transformer_linear.bias'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File('dataset/mead_25fps/processed/images/M003/front/disgusted/level_1/002/cropped_frames.hdf5', 'r') as f:\n",
    "    lmk_2d = torch.from_numpy(f['lmk_2d'][:])\n",
    "    img = torch.from_numpy(f['images'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = torch.arange(0, lmk_2d.shape[0])\n",
    "n, v = lmk_2d.shape[:2]\n",
    "lmk_mask = torch.ones(n, v)\n",
    "mouth_center = torch.mean(lmk_2d[frame_id, 257:258], dim=1).unsqueeze(1) # (nc, 1, 2)\n",
    "dw, dh = 0.2 + 0.4 * torch.rand(2) # ~uniform(0.2, 0.5)\n",
    "dist_to_center = (lmk_2d[frame_id] - mouth_center).abs() # (nc, V, 2)\n",
    "mask = (dist_to_center[...,0] < dw) & (dist_to_center[...,1] < dh)  # (nc, V)\n",
    "whole_mask = torch.zeros(n, v).bool()\n",
    "whole_mask[frame_id] = mask\n",
    "lmk_mask[whole_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3990), tensor(0.1681))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw, dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lmk_on_image(lmks, img, out_path, color=(0,0,255)):\n",
    "    # draw landmarks on the image\n",
    "    h, w, c = img.shape\n",
    "    for px in lmks[:,:2]:\n",
    "        x, y = int(px[0]), int(px[1])\n",
    "        if 0 <= x < w and 0 <=y < h:\n",
    "            cv2.circle(img, (x, y), 1, color, 1)\n",
    "    cv2.imwrite(out_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(388, 2)\n"
     ]
    }
   ],
   "source": [
    "lmk_0 = lmk_2d[0]\n",
    "lmk_mask_0 = lmk_mask[0]\n",
    "lmk_0 = lmk_0[lmk_mask_0.bool()]\n",
    "img_0 = (img[0,[2, 1, 0],:,:].permute(1,2,0) * 255.).numpy().astype(np.uint8).copy()\n",
    "print(img_0.shape)\n",
    "lmk_0 = (lmk_0 * 112 + 112).numpy().astype(int)\n",
    "print(lmk_0.shape)\n",
    "draw_lmk_on_image(lmk_0, img_0, 'test_eye_lmk_occlusion.png', color=(0,0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M003_level_2_contempt_001 SHE HAD YOUR DARK SUIT IN GREASY WASH WATER ALL YEAR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'dataset/list_full_mead_annotated.txt'\n",
    "file = open(file_path, \"r\")\n",
    "content=file.readlines()\n",
    "print(content[0])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M003_level_2_contempt_001',\n",
       " 'SHE HAD YOUR DARK SUIT IN GREASY WASH WATER ALL YEAR']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0].strip().split(' ', maxsplit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "sent_to_id = np.load('dataset/mead_25fps/processed/mead_sent_to_id.npy', allow_pickle=True)\n",
    "video_id_to_sent_id = dict()\n",
    "view = 'front'\n",
    "for line in content:\n",
    "    id, sent = line.strip().split(' ', maxsplit=1)\n",
    "    id_list = id.split('_')\n",
    "    sbj = id_list[0]\n",
    "    level = '_'.join([id_list[1], id_list[2]])\n",
    "    emotion = id_list[3]\n",
    "    sent_id_mead = id_list[4]\n",
    "    video_id = '/'.join([sbj, view, emotion, level, sent_id_mead])\n",
    "    video_id_to_sent_id[video_id] = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sent_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sent_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A FEW YEARS LATER THE DOME FELL IN BUT IN THIS ONE SECTION WE WELCOMED AUDITORS'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_set.difference(train_sent_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SHE HAD YOUR DARK SUIT IN GREASY WASH WATER ALL YEAR': 0,\n",
       " \"DON'T ASK ME TO CARRY AN OILY RAG LIKE THAT\": 1,\n",
       " 'WILL YOU TELL ME WHY': 2,\n",
       " \"ARE YOUR GRADES HIGHER OR LOWER THAN NANCY'S\": 3,\n",
       " 'THIS WAS EASY FOR US': 4,\n",
       " 'ONLY LAWYERS LOVE MILLIONAIRES': 5,\n",
       " \"IT'S ILLEGAL TO POSTDATE A CHECK\": 6,\n",
       " 'HE STOLE A DIME FROM A BEGGAR': 7,\n",
       " 'HIS FAILURE TO OPEN THE STORE BY EIGHT COST HIM HIS JOB': 8,\n",
       " 'LET US DIFFERENTIATE A FEW OF THESE IDEAS': 9,\n",
       " 'THE BIG DOG LOVED TO CHEW ON THE OLD RAG DOLL': 10,\n",
       " 'FAMILY LOYALTIES AND COOPERATIVE WORK HAVE BEEN UNBROKEN FOR GENERATIONS': 11,\n",
       " 'WITHDRAW ONLY AS MUCH MONEY AS YOU NEED': 12,\n",
       " 'THE WAY IS TO RENT A CHAUFFEUR DRIVEN CAR': 13,\n",
       " 'NO ONE MATERIAL IS BEST FOR ALL SITUATIONS': 14,\n",
       " 'MOSQUITOES EXIST IN WARM HUMID CLIMATES': 15,\n",
       " 'WE OF THE LIBERAL LED WORLD GOT ALL SET FOR PEACE AND REHABILITATION': 16,\n",
       " 'CAN YOUR INSURANCE COMPANY AID YOU IN REDUCING ADMINISTRATIVE COSTS': 17,\n",
       " 'SHE SPRANG UP AND WENT SWIFTLY TO THE BEDROOM': 18,\n",
       " 'TODD PLACED TOP PRIORITY ON GETTING HIS BIKE FIXED': 19,\n",
       " 'HE ATE FOUR EXTRA EGGS FOR BREAKFAST': 20,\n",
       " 'ONE EVEN GAVE MY LITTLE DOG A BISCUIT': 21,\n",
       " \"I'LL HAVE A SCOOP OF THAT EXOTIC PURPLE AND TURQUOISE SHERBET\": 22,\n",
       " 'HIS SUPERIORS HAD ALSO PREACHED THIS SAYING IT WAS THE WAY FOR ETERNAL HONOR': 23,\n",
       " 'LAND BASED RADAR WOULD HELP WITH THIS TASK': 24,\n",
       " 'IT WAS NOT WHATEVER TALE WAS TOLD BY TAILS': 25,\n",
       " 'NO THE MAN WAS NOT DRUNK HE WONDERED HOW HE GOT TIED UP WITH THIS STRANGER': 26,\n",
       " 'NO PRICE IS TOO HIGH WHEN TRUE LOVE IS AT STAKE': 27,\n",
       " 'THE REVOLUTION NOW UNDER WAY IN MATERIALS HANDLING MAKES THIS MUCH EASIER': 28,\n",
       " 'PLEASE TAKE THIS DIRTY TABLE CLOTH TO THE CLEANERS FOR ME': 29,\n",
       " 'THE SMALL BOY PUT THE WORM ON THE HOOK': 30,\n",
       " \"YOU'RE NOT LIVING UP TO YOUR OWN PRINCIPLES SHE TOLD MY DISCOURAGED PEOPLE\": 31,\n",
       " \"DON'T DO CHARLIE'S DIRTY DISHES\": 32,\n",
       " 'WILL ROBIN WEAR A YELLOW LILY': 33,\n",
       " 'YOUNG CHILDREN SHOULD AVOID EXPOSURE TO CONTAGIOUS DISEASES': 34,\n",
       " 'MILITARY PERSONNEL ARE EXPECTED TO OBEY GOVERNMENT ORDERS': 35,\n",
       " 'BASKETBALL CAN BE AN ENTERTAINING SPORT': 36,\n",
       " 'HOW GOOD IS YOUR ENDURANCE': 37,\n",
       " 'BARB BURNED PAPER AND LEAVES IN A BIG BONFIRE': 38,\n",
       " 'DECEMBER AND JANUARY ARE NICE MONTHS TO SPEND IN MIAMI': 39,\n",
       " 'IF PEOPLE WERE MORE GENEROUS THERE WOULD BE NO NEED FOR WELFARE': 40,\n",
       " 'IF THE FARM IS RENTED THE RENT MUST BE PAID': 41,\n",
       " 'PRETTY SOON A WOMAN CAME ALONG CARRYING A FOLDED UMBRELLA AS A WALKING STICK': 42,\n",
       " 'HOW MUCH AND HOW MANY PROFITS PROFITS COULD A MAJORITY TAKE OUT OF THE LOSSES OF A FEW': 43,\n",
       " 'DOES SOCIETY REALLY EXIST AS AN ENTITY OVER AND ABOVE THE AGGLOMERATION OF MEN': 44,\n",
       " 'THE PLAINTIFF IN SCHOOL DESEGREGATION CASES': 45,\n",
       " 'THOSE MUSICIANS HARMONIZE MARVELOUSLY': 46,\n",
       " 'THE EASTERN COAST IS A PLACE FOR PURE PLEASURE AND EXCITEMENT': 47,\n",
       " 'TIM TAKES SHEILA TO SEE MOVIES TWICE A WEEK': 48,\n",
       " 'THEY USED AN AGGRESSIVE POLICEMAN TO FLAG THOUGHTLESS MOTORISTS': 49,\n",
       " \"WHEN YOU'RE LESS FATIGUED THINGS JUST NATURALLY LOOK BRIGHTER\": 50,\n",
       " 'BY THAT TIME PERHAPS SOMETHING BETTER CAN BE DONE': 51,\n",
       " 'SHE FOUND HERSELF ABLE TO SING ANY ROLE AND ANY SONG WHICH STRUCK HER FANCY': 52,\n",
       " 'THAT NOISE PROBLEM GROWS MORE ANNOYING EACH DAY': 53,\n",
       " 'PROJECT DEVELOPMENT WAS PROCEEDING TOO SLOWLY': 54,\n",
       " 'THE OASIS WAS A MIRAGE': 55,\n",
       " 'SERVE THE COLESLAW AFTER I ADD THE OIL': 56,\n",
       " 'BY THAT ONE FEELS THAT MAGNETIC FORCES ARE AS GENERAL AS ELECTRICAL FORCES': 57,\n",
       " 'HIS ARTISTIC ACCOMPLISHMENTS GUARANTEED HIM ENTRY INTO ANY SOCIAL GATHERING': 58,\n",
       " 'HE WOULD NOT CARRY A BRIEF CASE': 59,\n",
       " 'OBVIOUSLY THE BRIDAL PAIR HAS MANY ADJUSTMENTS TO MAKE TO THEIR NEW SITUATION': 60,\n",
       " 'BOTH THE CONDITIONS AND THE COMPLICITY ARE DOCUMENTED IN CONSIDERABLE DETAIL': 61,\n",
       " 'WHO AUTHORIZED THE UNLIMITED EXPENSE ACCOUNT': 62,\n",
       " 'DESTROY EVERY FILE RELATED TO MY AUDITS': 63,\n",
       " \"THE CAT'S MEOW ALWAYS HURTS MY EARS\": 64,\n",
       " 'WHY ELSE WOULD DANNY ALLOW OTHERS TO GO': 65,\n",
       " 'WHY DO WE NEED BIGGER AND BETTER BOMBS': 66,\n",
       " 'NUCLEAR ROCKETS CAN DESTROY AIRFIELDS WITH EASE': 67,\n",
       " \"YOU'RE SO PREOCCUPIED THAT YOU'VE LET YOUR FAITH GROW DIM\": 68,\n",
       " 'CORY AND TRISH PLAYED TAG WITH BEACH BALLS FOR HOURS': 69,\n",
       " 'HE WILL ALLOW A RARE LIE': 70,\n",
       " 'WITHDRAW ALL PHONY ACCUSATIONS AT ONCE': 71,\n",
       " 'RIGHT NOW MAY NOT BE THE BEST TIME FOR BUSINESS MERGERS': 72,\n",
       " 'KINDERGARTEN CHILDREN DECORATE THEIR CLASSROOMS FOR ALL HOLIDAYS': 73,\n",
       " 'A FEW YEARS LATER THE DOME FELL IN': 74,\n",
       " 'BUT IN THIS ONE SECTION WE WELCOMED AUDITORS': 75,\n",
       " 'LOT OF PEOPLE WILL ROAM THE STREETS IN COSTUMES AND MASKS AND HAVING A BALL': 76,\n",
       " 'IN MANY OF HIS POEMS DEATH COMES BY TRAIN A STRONGLY EVOCATIVE VISUAL IMAGE': 77,\n",
       " 'THEN HE WOULD REALIZE THEY WERE REALLY THINGS THAT ONLY HE HIMSELF COULD THINK': 78,\n",
       " 'CALL AN AMBULANCE FOR MEDICAL ASSISTANCE': 79,\n",
       " \"TORNADO'S OFTEN DESTROY ACRES OF FARM LAND\": 80,\n",
       " 'WOULD YOU ALLOW ACTS OF VIOLENCE': 81,\n",
       " 'THE HIGH SECURITY PRISON WAS SURROUNDED BY BARBED WIRE': 82,\n",
       " 'HIS SHOULDER FELT AS IF IT WERE BROKEN': 83,\n",
       " 'THE FISH BEGAN TO LEAP FRANTICALLY ON THE SURFACE OF THE SMALL LAKE': 84,\n",
       " 'STRAW HATS ARE OUT OF FASHION THIS YEAR': 85,\n",
       " 'THAT DIAGRAM MAKES SENSE ONLY AFTER MUCH STUDY': 86,\n",
       " 'SPECIAL TASK FORCES RESCUE HOSTAGES FROM KIDNAPPERS': 87,\n",
       " \"THE TOOTH FAIRY FORGOT TO COME WHEN ROGER'S TOOTH FELL OUT\": 88,\n",
       " 'THEIR PROPS WERE TWO STEPLADDERS A CHAIR AND A PALM FAN': 89,\n",
       " 'THIS IS A PROBLEM THAT GOES CONSIDERABLY BEYOND QUESTIONS OF SALARY AND TENURE': 90,\n",
       " 'THE PULSING GLOW OF A CIGARETTE': 91,\n",
       " 'ONE LOOKED DOWN ON A SEA OF LEAVES A BREAKING WAVE OF FLOWER': 92,\n",
       " 'WE WILL ACHIEVE A MORE VIVID SENSE OF WHAT IT IS BY REALIZING WHAT IT IS NOT': 93,\n",
       " 'THE PROSPECT OF CUTTING BACK SPENDING IS AN UNPLEASANT ONE FOR ANY GOVERNOR': 94,\n",
       " 'THE DIAGNOSIS WAS DISCOURAGING HOWEVER HE WAS NOT OVERLY WORRIED': 95,\n",
       " 'WE CAN DIE TOO WE CAN DIE LIKE REAL PEOPLE PEOPLE NEVER LIVE FOREVER': 96,\n",
       " \"HE DIDN'T FIGURE HER AT ALL AND IF HE FOUND OUT A WOMAN IT'D BE BAD\": 97,\n",
       " 'THERE WOULD STILL BE PLENTY OF MOMENTS OF REGRET AND SADNESS AND GUILTY RELIEF': 98,\n",
       " 'SHE DRANK GREEDILY AND MURMURED THANK YOU AS HE LOWERED HER HEAD': 99,\n",
       " \"THERE'S NO CHANCE NOW OF ALL OF US GETTING AWAY\": 100,\n",
       " \"BEFORE THURSDAY'S EXAM REVIEW EVERY FORMULA\": 101,\n",
       " 'THEY ENJOY IT WHEN I AUDITION': 102,\n",
       " 'JOHN CLEANS SHELLFISH FOR A LIVING': 103,\n",
       " 'JEFF THOUGHT YOU ARGUED IN FAVOR OF A CENTRIFUGE PURCHASE': 104,\n",
       " 'HOWEVER THE LITTER REMAINED AUGMENTED BY SEVERAL DOZEN LUNCHROOM SUPPERS': 105,\n",
       " 'AMERICAN NEWSPAPER REVIEWERS LIKE TO CALL HIS PLAYS NIHILISTIC': 106,\n",
       " \"BUT THE SHIPS ARE VERY SLOW NOW AND WE DON'T GET SO MANY SAILORS ANY MORE\": 107,\n",
       " 'IT IS ONE OF THE RARE PUBLIC VENTURES HERE ON WHICH NEARLY EVERYONE IS AGREED': 108,\n",
       " 'NO MANUFACTURER HAS TAKEN THE INITIATIVE IN POINTING OUT THE COSTS INVOLVED': 109,\n",
       " 'THE CARPET CLEANERS SHAMPOOED OUR ORIENTAL RUG': 110,\n",
       " 'THE PATIENT AND THE SURGEON ARE BOTH RECUPERATING FROM THE LENGTHY OPERATION': 111,\n",
       " 'WHILE WAITING FOR CHIPPER SHE CRISSCROSSED THE SQUARE MANY TIMES': 112,\n",
       " 'I JUST SAW JIM NEAR THE NEW ARCHEOLOGICAL MUSEUM': 113,\n",
       " 'I TOOK HER WORD FOR IT BUT IS SHE REALLY GOING WITH YOU': 114,\n",
       " 'THE VIEWPOINT OVERLOOKED THE OCEAN': 115,\n",
       " \"I'D RIDE THE SUBWAY BUT I HAVEN'T ENOUGH CHANGE\": 116,\n",
       " 'THE CLUMSY CUSTOMER SPILLED SOME EXPENSIVE PERFUME': 117,\n",
       " 'PLEASE DIG MY POTATOES UP BEFORE FROST': 118,\n",
       " 'GRANDMOTHER OUTGREW HER UPBRINGING IN PETTICOATS': 119,\n",
       " 'SALVATION RECONSIDERED': 120,\n",
       " 'PROPERLY USED THE PRESENT BOOK IS AN EXCELLENT INSTRUMENT OF ENLIGHTENMENT': 121,\n",
       " 'LIGHTED WINDOWS GLOWED JEWEL BRIGHT THROUGH THE DOWNPOUR': 122,\n",
       " \"BUT THIS DOESN'T DETRACT FROM ITS MERIT AS AN INTERESTING IF NOT GREAT FILM\": 123,\n",
       " 'HE FURTHER PROPOSED GRANTS OF AN UNSPECIFIED SUM FOR EXPERIMENTAL HOSPITALS': 124,\n",
       " \"DON'T DO CHARLIE'S DIRTY DIRTY DISHES\": 125,\n",
       " 'LABORATORY ASTROPHYSICS': 126,\n",
       " 'HOW MUCH AND HOW MANY PROFITS COULD A MAJORITY TAKE OUT OF THE LOSSES OF A FEW': 127,\n",
       " 'THE PLAINTIFF IN SCHOOL DESEGREGATION': 128,\n",
       " 'BRIDGES TUNNELS AND FERRIES ARE THE MOST COMMON METHODS OF RIVER CROSSINGS': 129,\n",
       " 'THE MOMENT OF TRUTH IS THE MOMENT OF CRISIS': 130,\n",
       " 'THE BEST WAY TO LEARN IS TO SOLVE EXTRA PROBLEMS': 131,\n",
       " 'THEREUPON FOLLOWED A DEMONSTRATION THAT TYRANNY KNOWS NO IDEOLOGICAL CONFINES': 132,\n",
       " 'CALCIUM MAKES BONES AND TEETH STRONG': 133,\n",
       " 'CATASTROPHIC ECONOMIC CUTBACKS NEGLECT THE POOR': 134,\n",
       " 'ALLOW LEEWAY HERE BUT RATIONALIZE ALL ERRORS': 135,\n",
       " 'GREG BUYS FRESH MILK EACH WEEKDAY MORNING': 136,\n",
       " 'AGRICULTURAL PRODUCTS ARE UNEVENLY DISTRIBUTED': 137,\n",
       " 'THE NEAREST SYNAGOGUE MAY NOT BE WITHIN WALKING DISTANCE': 138,\n",
       " 'AS SUCH IT WAS BEYOND POLITICS AND HAD NO NEED OF JUSTIFICATION BY A MESSAGE': 139,\n",
       " 'HE ALWAYS SEEMED TO HAVE MONEY IN HIS POCKET': 140,\n",
       " 'NO RETURN ADDRESS WHATSOEVER': 141,\n",
       " 'KEEP YOUR SEATS BOYS I JUST WANT TO PUT SOME FINISHING TOUCHES ON THIS THING': 142,\n",
       " 'HE RIPPED DOWN THE CELLOPHANE CAREFULLY AND LAID THREE DOGS ON THE TIN FOIL': 143,\n",
       " 'DON’T ASK ME TO CARRY AN OILY RAG LIKE THAT': 144,\n",
       " 'ARE YOUR GRADES HIGHER OR LOWER THAN NANCY’S': 145,\n",
       " 'IT’S ILLEGAL TO POSTDATE A CHECK': 146,\n",
       " 'I’LL HAVE A SCOOP OF THAT EXOTIC PURPLE AND TURQUOISE SHERBET': 147,\n",
       " 'YOU’RE NOT LIVING UP TO YOUR OWN PRINCIPLES SHE TOLD MY DISCOURAGED PEOPLE': 148,\n",
       " 'DON’T DO CHARLIE’S DIRTY DISHES': 149,\n",
       " 'WHEN YOU’RE LESS FATIGUED THINGS JUST NATURALLY LOOK BRIGHTER': 150,\n",
       " 'THE CAT’S MEOW ALWAYS HURTS MY EARS': 151,\n",
       " 'YOU’RE SO PREOCCUPIED THAT YOU’VE LET YOUR FAITH GROW DIM': 152,\n",
       " 'TORNADO’S OFTEN DESTROY ACRES OF FARM LAND': 153,\n",
       " 'THE TOOTH FAIRY FORGOT TO COME WHEN ROGER’S TOOTH FELL OUT': 154,\n",
       " 'HE DIDN’T FIGURE HER AT ALL AND IF HE FOUND OUT A WOMAN IT’D BE BAD': 155,\n",
       " 'THERE’S NO CHANCE NOW OF ALL OF US GETTING AWAY': 156,\n",
       " 'BEFORE THURSDAY’S EXAM REVIEW EVERY FORMULA': 157,\n",
       " 'BUT THE SHIPS ARE VERY SLOW NOW AND WE DON’T GET SO MANY SAILORS ANY MORE': 158,\n",
       " 'I’D RIDE THE SUBWAY BUT I HAVEN’T ENOUGH CHANGE': 159,\n",
       " 'BUT THIS DOESN’T DETRACT FROM ITS MERIT AS AN INTERESTING IF NOT GREAT FILM': 160,\n",
       " 'KINDERGARTEN CHILDREN DECORATE THEIR CLASSROOMS FOR ALL HOLIDAYS A FEW YEARS LATER THE DOME FELL IN': 161,\n",
       " 'HIS SHOULDER FELT AS IF IT WERE BROKEN THE FISH BEGAN TO LEAP FRANTICALLY ON THE SURFACE OF THE SMALL LAKE': 162,\n",
       " 'A FEW YEARS LATER THE DOME FELL IN BUT IN THIS ONE SECTION WE WELCOMED AUDITORS': 163,\n",
       " 'NO PRICE IS TOO HIGH WHEN TRUE LOVE IS AT STAKEW02': 164}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
