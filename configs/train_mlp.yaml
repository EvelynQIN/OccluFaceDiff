save_dir: "./checkpoints/PureMLP_expression_norm" 
num_epoch: 15
dataset: "FaMoS" 
dataset_path: "./processed_data"
weight_decay: 0.0001
batch_size: 128
lr: 0.0003
save_interval: 1 
log_interval: 1 
device: 0 
layers: 12 
train_dataset_repeat_times: 100 
lr_anneal_steps: 225000 
overwrite: True 
no_normalization: False
wandb_log: True

# model architechture
arch: "mlp_PureMLP_norm" 
num_workers: 8 
motion_nfeat: 100
sparse_dim: 204 # (68x3)
latent_dim: 512 
input_motion_length: 150 

# for flame
flame_model_path: "flame_2020/generic_model.pkl"
flame_lmk_embedding_path: "flame_2020/landmark_embedding.npy"